{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"mpg\", \"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"model year\", \"origin\", \"car name\"]\n",
    "cars = pd.read_table(\"auto-mpg.data\", delim_whitespace=True, names=columns)\n",
    "filtered_cars = cars[cars['horsepower'] != '?'].copy()\n",
    "filtered_cars['horsepower'] = filtered_cars['horsepower'].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the heart of understanding overfitting is understanding bias and variance. Bias and variance make up the 2 observable sources of error in a model that we can indirectly control.\n",
    "\n",
    "Bias describes error that results in bad assumptions about the learning algorithm. For example, assuming that only one feature, like a car's weight, relates to a car's fuel efficiency will lead you to fit a simple, univariate regression model that will result in high bias. The error rate will be high since a car's fuel efficiency is affected by many other factors besides just its weight.\n",
    "\n",
    "Variance describes error that occurs because of the variability of a model's predicted values. If we were given a dataset with 1000 features on each car and used every single feature to train an incredibly complicated multivariate regression model, we will have low bias but high variance.\n",
    "\n",
    "In an ideal world, we want low bias and low variance but in reality, there's always a tradeoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(cols):\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(filtered_cars[cols], filtered_cars['mpg'])\n",
    "    predictions = lr.predict(filtered_cars[cols])\n",
    "    mse = mean_squared_error(predictions, filtered_cars['mpg'])\n",
    "    variance = predictions.var()\n",
    "    return (mse, variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cylinder 24.0201795682 36.7425588742\n",
      "weight 18.6766165974 42.0861218449\n"
     ]
    }
   ],
   "source": [
    "cyl_mse, cyl_var = train_and_test(['cylinders'])\n",
    "weight_mse, weight_var = train_and_test(['weight'])\n",
    "print('cylinder', cyl_mse, cyl_var)\n",
    "print('weight', weight_mse, weight_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_mse, one_var = train_and_test([\"cylinders\"])\n",
    "two_mse, two_var = train_and_test([\"cylinders\", \"displacement\"])\n",
    "three_mse, three_var = train_and_test([\"cylinders\", \"displacement\", \"horsepower\"])\n",
    "four_mse, four_var = train_and_test([\"cylinders\", \"displacement\", \"horsepower\", \"weight\"])\n",
    "five_mse, five_var = train_and_test([\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\"])\n",
    "six_mse, six_var = train_and_test([\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"model year\"])\n",
    "seven_mse, seven_var = train_and_test([\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\",\"model year\", \"origin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.0201795682 36.7425588742\n",
      "21.2820570556 39.4806813867\n",
      "20.2529548397 40.5097836026\n",
      "17.7638605718 42.9988778705\n",
      "17.7613961054 43.0013423369\n",
      "11.5901709814 49.1725674609\n",
      "10.847480945 49.9152574973\n"
     ]
    }
   ],
   "source": [
    "print(one_mse, one_var)\n",
    "print(two_mse, two_var)\n",
    "print(three_mse, three_var)\n",
    "print(four_mse, four_var)\n",
    "print(five_mse, five_var)\n",
    "print(six_mse, six_var)\n",
    "print(seven_mse, seven_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_cross_val(cols):\n",
    "    features = filtered_cars[cols]\n",
    "    target = filtered_cars[\"mpg\"]\n",
    "    \n",
    "    variance_values = []\n",
    "    mse_values = []\n",
    "    \n",
    "    # KFold instance.\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=3)\n",
    "    \n",
    "    # Iterate through over each fold.\n",
    "    for train_index, test_index in kf.split(features):\n",
    "        # Training and test sets.\n",
    "        X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "        y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "        \n",
    "        # Fit the model and make predictions.\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(X_train, y_train)\n",
    "        predictions = lr.predict(X_test)\n",
    "        \n",
    "        # Calculate mse and variance values for this fold.\n",
    "        mse = mean_squared_error(y_test, predictions)\n",
    "        var = np.var(predictions)\n",
    "\n",
    "        # Append to arrays to do calculate overall average mse and variance values.\n",
    "        variance_values.append(var)\n",
    "        mse_values.append(mse)\n",
    "   \n",
    "    # Compute average mse and variance values.\n",
    "    avg_mse = np.mean(mse_values)\n",
    "    avg_var = np.mean(variance_values)\n",
    "    return(avg_mse, avg_var)\n",
    "        \n",
    "two_mse, two_var = train_and_cross_val([\"cylinders\", \"displacement\"])\n",
    "three_mse, three_var = train_and_cross_val([\"cylinders\", \"displacement\", \"horsepower\"])\n",
    "four_mse, four_var = train_and_cross_val([\"cylinders\", \"displacement\", \"horsepower\", \"weight\"])\n",
    "five_mse, five_var = train_and_cross_val([\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\"])\n",
    "six_mse, six_var = train_and_cross_val([\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"model year\"])\n",
    "seven_mse, seven_var = train_and_cross_val([\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\",\"model year\", \"origin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.0201795682 36.7425588742\n",
      "21.584370275 38.9025253138\n",
      "20.6556221939 40.0912879566\n",
      "18.1696832391 42.5076436436\n",
      "18.2830385172 42.5987363001\n",
      "12.0996854255 48.9282469677\n",
      "11.4181319718 49.904313731\n"
     ]
    }
   ],
   "source": [
    "print(one_mse, one_var)\n",
    "print(two_mse, two_var)\n",
    "print(three_mse, three_var)\n",
    "print(four_mse, four_var)\n",
    "print(five_mse, five_var)\n",
    "print(six_mse, six_var)\n",
    "print(seven_mse, seven_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter([2,3,4,5,6,7], [two_mse, three_mse, four_mse, five_mse, six_mse, seven_mse], c='red')\n",
    "plt.scatter([2,3,4,5,6,7], [two_var, three_var, four_var, five_var, six_var, seven_var], c='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dataquest)",
   "language": "python",
   "name": "dataquest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
